{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the .ldata file using pandas\n",
    "\n",
    "columns = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "df = pd.read_csv('./auto-mpg.data', names = columns, na_values = \"?\", comment = '\\t', sep = \" \", skipinitialspace = True)\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\n",
    "\n",
    "for train_index, test_index, in split.split(data, data[\"Cylinders\"]):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Cylinders  Displacement  Horsepower  Weight  Acceleration  Model Year  \\\n145          4          83.0        61.0  2003.0          19.0          74   \n151          4          79.0        67.0  2000.0          16.0          74   \n388          4         156.0        92.0  2585.0          14.5          82   \n48           6         250.0        88.0  3139.0          14.5          71   \n114          4          98.0        90.0  2265.0          15.5          73   \n..         ...           ...         ...     ...           ...         ...   \n147          4          90.0        75.0  2108.0          15.5          74   \n156          8         400.0       170.0  4668.0          11.5          75   \n395          4         135.0        84.0  2295.0          11.6          82   \n14           4         113.0        95.0  2372.0          15.0          70   \n362          6         146.0       120.0  2930.0          13.8          81   \n\n     Origin  \n145       3  \n151       2  \n388       1  \n48        1  \n114       2  \n..      ...  \n147       2  \n156       1  \n395       1  \n14        3  \n362       3  \n\n[318 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cylinders</th>\n      <th>Displacement</th>\n      <th>Horsepower</th>\n      <th>Weight</th>\n      <th>Acceleration</th>\n      <th>Model Year</th>\n      <th>Origin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>145</td>\n      <td>4</td>\n      <td>83.0</td>\n      <td>61.0</td>\n      <td>2003.0</td>\n      <td>19.0</td>\n      <td>74</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>151</td>\n      <td>4</td>\n      <td>79.0</td>\n      <td>67.0</td>\n      <td>2000.0</td>\n      <td>16.0</td>\n      <td>74</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>388</td>\n      <td>4</td>\n      <td>156.0</td>\n      <td>92.0</td>\n      <td>2585.0</td>\n      <td>14.5</td>\n      <td>82</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>6</td>\n      <td>250.0</td>\n      <td>88.0</td>\n      <td>3139.0</td>\n      <td>14.5</td>\n      <td>71</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>114</td>\n      <td>4</td>\n      <td>98.0</td>\n      <td>90.0</td>\n      <td>2265.0</td>\n      <td>15.5</td>\n      <td>73</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>147</td>\n      <td>4</td>\n      <td>90.0</td>\n      <td>75.0</td>\n      <td>2108.0</td>\n      <td>15.5</td>\n      <td>74</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>156</td>\n      <td>8</td>\n      <td>400.0</td>\n      <td>170.0</td>\n      <td>4668.0</td>\n      <td>11.5</td>\n      <td>75</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>395</td>\n      <td>4</td>\n      <td>135.0</td>\n      <td>84.0</td>\n      <td>2295.0</td>\n      <td>11.6</td>\n      <td>82</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>4</td>\n      <td>113.0</td>\n      <td>95.0</td>\n      <td>2372.0</td>\n      <td>15.0</td>\n      <td>70</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>362</td>\n      <td>6</td>\n      <td>146.0</td>\n      <td>120.0</td>\n      <td>2930.0</td>\n      <td>13.8</td>\n      <td>81</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>318 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#separate feature and target variable\n",
    "data = strat_train_set.drop(\"MPG\", axis = 1)\n",
    "data_labels = strat_train_set[\"MPG\"].copy()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the Origin column in data\n",
    "def preprocess_origin_column(df):\n",
    "    df[\"Origin\"] = df[\"Origin\"].map(\n",
    "        {\n",
    "            1: \"India\",\n",
    "            2: \"USA\",\n",
    "            3: \"Germany\"\n",
    "        }\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating custom attribute class \n",
    "\n",
    "acceleration_index, horsepower_index, cylinder_index = 4, 2, 0\n",
    "\n",
    "class CustomAttributeAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, acceleration_on_power = True):\n",
    "        self.acceleration_on_power = acceleration_on_power\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform (self, X):\n",
    "        acceleration_on_cylinder = X[:, acceleration_index] / X[:, cylinder_index]\n",
    "        if self.acceleration_on_power == True:\n",
    "            acceleration_on_power = X[:, acceleration_index] / X[:, horsepower_index]\n",
    "            return np.c_[X, acceleration_on_power, acceleration_on_cylinder]\n",
    "        return np.c[X, acceleration_on_cylinder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the pipeline\n",
    "\n",
    "def numerical_pipeline_transformer(data):\n",
    "    '''\n",
    "    Processes numerical transformations of the dataframe and calls the pipeline class and creates a pipeline.\n",
    "    Imputes missing values with the median value\n",
    "    Adds custom attribute acceleration_on_power and acceleration_on_cylinder\n",
    "    Scales numerical attributes with StandardScaler\n",
    "\n",
    "    '''\n",
    "    numerics = ['float64', 'int64']\n",
    "\n",
    "    numerical_attributes = data.select_dtypes(include = numerics)\n",
    "\n",
    "    numerical_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy= \"median\")),\n",
    "        (\"attrs_adder\", CustomAttributeAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "    return numerical_attributes, numerical_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_transformer (data):\n",
    "    '''\n",
    "    Completes transformation pipeline for numerical and categorical data.\n",
    "    One-hot encodes categorical data\n",
    "    '''\n",
    "    categorical_attributes = [\"Origin\"]\n",
    "    numerical_attributes, numerical_pipeline = numerical_pipeline_transformer(data)\n",
    "\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        (\"num\", numerical_pipeline, list(numerical_attributes)),\n",
    "        (\"cat\", OneHotEncoder(), categorical_attributes),\n",
    "    ])\n",
    "    prepared_data = full_pipeline.fit_transform(data)\n",
    "    return prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from raw data to processed data\n",
    "preprocessed_df = preprocess_origin_column(data)\n",
    "prepared_data = pipeline_transformer(preprocessed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[-0.85657842, -1.07804475, -1.15192977, ...,  1.        ,\n         0.        ,  0.        ],\n       [-0.85657842, -1.1174582 , -0.9900351 , ...,  0.        ,\n         0.        ,  1.        ],\n       [-0.85657842, -0.3587492 , -0.31547399, ...,  0.        ,\n         1.        ,  0.        ],\n       ...,\n       [-0.85657842, -0.56566984, -0.53133355, ...,  0.        ,\n         1.        ,  0.        ],\n       [-0.85657842, -0.78244384, -0.23452666, ...,  1.        ,\n         0.        ,  0.        ],\n       [ 0.32260746, -0.45728283,  0.44003446, ...,  1.        ,\n         0.        ,  0.        ]])"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([-0.85657842, -1.07804475, -1.15192977, -1.17220298,  1.21586943,\n       -0.54436373,  1.70952741,  1.29565517,  1.        ,  0.        ,\n        0.        ])"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "prepared_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Cylinders  Displacement  Horsepower  Weight  Acceleration  Model Year  \\\n145          4          83.0        61.0  2003.0          19.0          74   \n151          4          79.0        67.0  2000.0          16.0          74   \n388          4         156.0        92.0  2585.0          14.5          82   \n48           6         250.0        88.0  3139.0          14.5          71   \n114          4          98.0        90.0  2265.0          15.5          73   \n..         ...           ...         ...     ...           ...         ...   \n147          4          90.0        75.0  2108.0          15.5          74   \n156          8         400.0       170.0  4668.0          11.5          75   \n395          4         135.0        84.0  2295.0          11.6          82   \n14           4         113.0        95.0  2372.0          15.0          70   \n362          6         146.0       120.0  2930.0          13.8          81   \n\n      Origin  \n145  Germany  \n151      USA  \n388    India  \n48     India  \n114      USA  \n..       ...  \n147      USA  \n156    India  \n395    India  \n14   Germany  \n362  Germany  \n\n[318 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cylinders</th>\n      <th>Displacement</th>\n      <th>Horsepower</th>\n      <th>Weight</th>\n      <th>Acceleration</th>\n      <th>Model Year</th>\n      <th>Origin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>145</td>\n      <td>4</td>\n      <td>83.0</td>\n      <td>61.0</td>\n      <td>2003.0</td>\n      <td>19.0</td>\n      <td>74</td>\n      <td>Germany</td>\n    </tr>\n    <tr>\n      <td>151</td>\n      <td>4</td>\n      <td>79.0</td>\n      <td>67.0</td>\n      <td>2000.0</td>\n      <td>16.0</td>\n      <td>74</td>\n      <td>USA</td>\n    </tr>\n    <tr>\n      <td>388</td>\n      <td>4</td>\n      <td>156.0</td>\n      <td>92.0</td>\n      <td>2585.0</td>\n      <td>14.5</td>\n      <td>82</td>\n      <td>India</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>6</td>\n      <td>250.0</td>\n      <td>88.0</td>\n      <td>3139.0</td>\n      <td>14.5</td>\n      <td>71</td>\n      <td>India</td>\n    </tr>\n    <tr>\n      <td>114</td>\n      <td>4</td>\n      <td>98.0</td>\n      <td>90.0</td>\n      <td>2265.0</td>\n      <td>15.5</td>\n      <td>73</td>\n      <td>USA</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>147</td>\n      <td>4</td>\n      <td>90.0</td>\n      <td>75.0</td>\n      <td>2108.0</td>\n      <td>15.5</td>\n      <td>74</td>\n      <td>USA</td>\n    </tr>\n    <tr>\n      <td>156</td>\n      <td>8</td>\n      <td>400.0</td>\n      <td>170.0</td>\n      <td>4668.0</td>\n      <td>11.5</td>\n      <td>75</td>\n      <td>India</td>\n    </tr>\n    <tr>\n      <td>395</td>\n      <td>4</td>\n      <td>135.0</td>\n      <td>84.0</td>\n      <td>2295.0</td>\n      <td>11.6</td>\n      <td>82</td>\n      <td>India</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>4</td>\n      <td>113.0</td>\n      <td>95.0</td>\n      <td>2372.0</td>\n      <td>15.0</td>\n      <td>70</td>\n      <td>Germany</td>\n    </tr>\n    <tr>\n      <td>362</td>\n      <td>6</td>\n      <td>146.0</td>\n      <td>120.0</td>\n      <td>2930.0</td>\n      <td>13.8</td>\n      <td>81</td>\n      <td>Germany</td>\n    </tr>\n  </tbody>\n</table>\n<p>318 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting and training models (Linear Regression, Decision Tree, Random Forest, SVM regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(prepared_data, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Prediction of samples:  [29.08069379 27.78336755 26.08031176 12.70419279 22.23454159]\n"
    }
   ],
   "source": [
    "#testing predictions with the Linear Regression Model\n",
    "sample_data = data.iloc[:5]\n",
    "sample_labels = data_labels.iloc[:5]\n",
    "\n",
    "sample_data_prepared = pipeline_transformer(sample_data)\n",
    "\n",
    "print(\"Prediction of samples: \", lin_reg.predict(sample_data_prepared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Actual label of samples:  [32.0, 31.0, 26.0, 18.0, 26.0]\n"
    }
   ],
   "source": [
    "#ctual label of the samples\n",
    "print(\"Actual label of samples: \", list(sample_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2.9590402225760872"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "#Root Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mpg_predictions = lin_reg.predict(prepared_data)\n",
    "lin_mse = mean_squared_error(data_labels, mpg_predictions) #these are the means squared error\n",
    "lin_rmse = np.sqrt(lin_mse) #this finds the root meansquare error\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n                      min_impurity_split=None, min_samples_leaf=1,\n                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n                      presort=False, random_state=None, splitter='best')"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(prepared_data, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "mpg_predictions = tree_reg.predict(prepared_data)\n",
    "tree_mse = mean_squared_error(data_labels, mpg_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The zero indicates the model overfits the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation using cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(\n",
    "    tree_reg,\n",
    "    prepared_data,\n",
    "    data_labels,\n",
    "    scoring = \"neg_mean_squared_error\",\n",
    "    cv = 10\n",
    ")\n",
    "\n",
    "tree_reg_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2.90032326, 3.12179836, 3.26668793, 3.32387199, 2.26460537,\n       3.13119386, 3.57368857, 4.99096058, 4.2603574 , 2.59403783])"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "tree_reg_rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3.3427525144561456"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "tree_reg_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([3.43254597, 3.45157629, 3.6621715 , 2.59652976, 2.48023405,\n       2.74798115, 3.32524647, 2.42208917, 3.78133275, 2.8573747 ])"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "scores = cross_val_score( \n",
    "     lin_reg,\n",
    "     prepared_data,\n",
    "     data_labels,\n",
    "     scoring = \"neg_mean_squared_error\",\n",
    "     cv = 10\n",
    ")\n",
    "\n",
    "lin_reg_rmse_scores = np.sqrt(-scores)\n",
    "lin_reg_rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3.075708179370933"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "lin_reg_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Model\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(prepared_data, data_labels)\n",
    "forest_reg_cv_scores = cross_val_score( \n",
    "    forest_reg,\n",
    "    prepared_data,\n",
    "    data_labels,\n",
    "    scoring = 'neg_mean_squared_error',\n",
    "    cv = 10\n",
    ")\n",
    "\n",
    "forest_reg_rmse_scores = np.sqrt(-forest_reg_cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2.7289837027131165"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "forest_reg_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support vector machine regressor\n",
    "\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_reg = SVR(kernel = 'linear')\n",
    "svm_reg.fit(prepared_data, data_labels)\n",
    "svm_cv_scores = cross_val_score(svm_reg, prepared_data, data_labels, scoring = 'neg_mean_squared_error', cv = 10)\n",
    "\n",
    "svm_rmse_scores = np.sqrt(-svm_cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3.08659162080283"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "svm_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So far Random Forest performs the best due to lowest rmse mean score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning  of the Random Forest using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=10, error_score='raise-deprecating',\n             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n                                             max_depth=None,\n                                             max_features='auto',\n                                             max_leaf_nodes=None,\n                                             min_impurity_decrease=0.0,\n                                             min_impurity_split=None,\n                                             min_samples_leaf=1,\n                                             min_samples_split=2,\n                                             min_weight_fraction_leaf=0.0,\n                                             n_estimators='warn', n_jobs=None,\n                                             oob_score=False, random_state=None,\n                                             verbose=0, warm_start=False),\n             iid='warn', n_jobs=None,\n             param_grid=[{'max_features': [2, 4, 6, 8],\n                          'n_estimators': [3, 10, 30]},\n                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n                          'n_estimators': [3, 10]}],\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n             scoring='neg_mean_squared_error', verbose=0)"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "param_grid = [ \n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3,10], 'max_features': [2, 3,4]},\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, scoring = 'neg_mean_squared_error', return_train_score=True, cv = 10)\n",
    "\n",
    "grid_search.fit(prepared_data, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'max_features': 8, 'n_estimators': 30}"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3.51465286563239 {'max_features': 2, 'n_estimators': 3}\n3.0816848389380898 {'max_features': 2, 'n_estimators': 10}\n2.8664177894012988 {'max_features': 2, 'n_estimators': 30}\n3.0843080220436425 {'max_features': 4, 'n_estimators': 3}\n2.901622838057976 {'max_features': 4, 'n_estimators': 10}\n2.73033841810104 {'max_features': 4, 'n_estimators': 30}\n3.2641194664082573 {'max_features': 6, 'n_estimators': 3}\n2.913702177189441 {'max_features': 6, 'n_estimators': 10}\n2.72471972670558 {'max_features': 6, 'n_estimators': 30}\n3.0581546026524995 {'max_features': 8, 'n_estimators': 3}\n2.7057133820233763 {'max_features': 8, 'n_estimators': 10}\n2.7039400232246957 {'max_features': 8, 'n_estimators': 30}\n3.0509057435530065 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n2.8247267914863694 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n3.0431092038956447 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n2.9410906931627943 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n3.2049364658016697 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n2.8541770669598874 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
    }
   ],
   "source": [
    "cv_scores = grid_search.cv_results_\n",
    "\n",
    "for mean_score, params in zip(cv_scores['mean_test_score'], cv_scores[\"params\"]):\n",
    "    print(np.sqrt(-mean_score),params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: Max-Features = 8, n_estimators 30 is lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.13477121, 0.26346519, 0.15892413, 0.22154053, 0.01517216,\n       0.12192137, 0.02209112, 0.05590248, 0.00211967, 0.00250131,\n       0.00159084])"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('acceleration_on_power', 0.022091120537969914),\n ('acceleration_on_cylinder', 0.05590247907289417),\n ('Weight', 0.22154052681729497),\n ('Model Year', 0.12192136739918782),\n ('Horsepower', 0.15892413014460505),\n ('Displacement', 0.2634651852000586),\n ('Cylinders', 0.13477121256514996),\n ('Acceleration', 0.015172157884237644)]"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "extra_attributes = [\"acceleration_on_power\", \"acceleration_on_cylinder\"]\n",
    "numerics = ['float64', 'int64']\n",
    "numerical_attributes = list(data.select_dtypes(include = numerics))\n",
    "\n",
    "attributes = numerical_attributes + extra_attributes\n",
    "sorted(zip(attributes, feature_importances), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the entire system on test data\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"MPG\", axis = 1)\n",
    "y_test = strat_test_set[\"MPG\"].copy()\n",
    "\n",
    "X_test_preprocessed = preprocess_origin_column(X_test)\n",
    "X_test_prepared = pipeline_transformer(X_test_preprocessed)\n",
    "\n",
    "final_prediction = final_model.predict(X_test_prepared)\n",
    "final_mse = mean_squared_error(y_test, final_prediction)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2.9152637816613898"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a funciton to cover this entire flow \n",
    "\n",
    "def predict_mpg(config, model):\n",
    "    if type(config) == dict:\n",
    "        df = pd.DataFrame(config)\n",
    "    else:\n",
    "        df = config\n",
    "\n",
    "    preproc_df = preprocess_origin_column(df)\n",
    "    prepared_df = pipeline_transformer(preproc_df)\n",
    "    print(prepared_df)\n",
    "    y_pred = model.predict(prepared_df)\n",
    "    return y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[-1.22474487 -1.20484922 -0.85412443 -0.87481777  0.          1.06904497\n   0.6684025   1.39127885  1.          0.          0.        ]\n [ 0.         -0.0388661   1.40320441  1.39970842 -1.22474487  0.26726124\n  -1.41351982 -0.47596382  0.          0.          1.        ]\n [ 1.22474487  1.24371532 -0.54907999 -0.52489066  1.22474487 -1.33630621\n   0.74511732 -0.91531503  0.          1.          0.        ]]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([36.07      , 16.90333333, 20.32      ])"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "#checking in on a random sample\n",
    "vehicle_config = { \n",
    "    'Cylinders' : [4, 6, 8],\n",
    "    'Displacement' : [155.0, 160.0, 165.5],\n",
    "    'Horsepower' : [93.0, 130.0, 98.0],\n",
    "    'Weight' : [2500.0, 3150.0,  2600.0],\n",
    "    'Acceleration' : [15.0, 14.0, 16.0],\n",
    "    'Model Year': [81, 80, 78],\n",
    "    'Origin' : [3, 2, 1]\n",
    "}\n",
    "\n",
    "predict_mpg(vehicle_config, final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.bin\", \"wb\") as f_out:\n",
    "    pickle.dump(final_model, f_out)\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model from the saved file\n",
    "with open('model.bin', 'rb') as f_in:\n",
    "    model = pickle.load(f_in)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[-1.22474487 -1.20484922 -0.85412443 -0.87481777  0.          1.06904497\n   0.6684025   1.39127885  1.          0.          0.        ]\n [ 0.         -0.0388661   1.40320441  1.39970842 -1.22474487  0.26726124\n  -1.41351982 -0.47596382  0.          0.          1.        ]\n [ 1.22474487  1.24371532 -0.54907999 -0.52489066  1.22474487 -1.33630621\n   0.74511732 -0.91531503  0.          1.          0.        ]]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([36.07      , 16.90333333, 20.32      ])"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "predict_mpg(vehicle_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}